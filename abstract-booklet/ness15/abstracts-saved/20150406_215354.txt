poster
@@$$@@$$@@
00
@@$$@@$$@@
Implicit stochastic gradient descent for principled estimation with large datasets
@@$$@@$$@@
Panos Toulis
Harvard University
ptoulis@fas.harvard.edu

@@$$@@$$@@
1
@@$$@@$$@@
Efficient optimization procedures, such as stochastic gradient descent, have been gaining popularity for estimation tasks with large amounts of data. Typically these procedures are iterative and use \emph{explicit} iterates, where the update at every iteration depends on the 
previous iterate and one observed datapoint. 
In this paper, we introduce an \emph{implicit} stochastic gradient descent estimation procedure that uses iterates that are implicitly defined. The implicit iterates are \emph{shrinked} versions of explicit iterates, and it can be shown that the amount of shrinkage depends on the observed Fisher information, but this latter quantity needs not be directly computed. The implicit procedure is thus robust to the choice of a scalar hyper-parameter in stochastic gradient descent, known as the learning rate, that affects its asymptotic statistical properties. In contrast, explicit procedures require the learning rate to agree with the eigenvalues of the Fisher information matrix of the underlying model parameters in order to be stable.
%
In the context of generalized linear models, we derive analytic formulas for the asymptotic bias and variance of both procedures as estimation methods, and quantify their efficiency loss compared to maximum likelihood.
%
Our analysis naturally extends to exponential family models, and to a general class of estimation methods through Monte-Carlo stochastic gradient descent, in problems where the likelihood is hard to compute but where it is easy to sample from the underlying model.  We demonstrate our theory in an extensive set of experiments involving real and simulated data. Implicit stochastic gradient descent compares favorably to 
popular estimation methods that use explicit iterates. 
Additionally, it provides principled estimators 
that are numerically stable and can be trusted to have the 
nominal theoretical variance.